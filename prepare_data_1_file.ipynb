{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "\n",
    "shuffle_data = True  # shuffle the addresses before saving\n",
    "hdf5_path = 'chest_xray.hdf5'  # address to where you want to save the hdf5 file\n",
    "normal_images_path = 'images/normal/*.jpeg'\n",
    "pneumonia_images_path = 'images/pneumonia/*.jpeg'\n",
    "\n",
    "# read addresses and labels from the 'train' folder\n",
    "normal_addrs = glob.glob(normal_images_path)\n",
    "pneumonia_addrs = glob.glob(pneumonia_images_path)\n",
    "\n",
    "addrs = normal_addrs + pneumonia_addrs\n",
    "#print(addrs)\n",
    "\n",
    "labels = [0 if 'normal' in addr else 1 for addr in addrs]  # 0 = normal, 1 = pneumonia\n",
    "#print(labels)\n",
    "\n",
    "# to shuffle data\n",
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c)\n",
    "    addrs, labels = zip(*c)\n",
    "\n",
    "#print(labels)\n",
    "# Divide the hata into 60% train, 20% validation, and 20% test\n",
    "train_addrs = addrs[0:int(0.8*len(addrs))]\n",
    "train_labels = labels[0:int(0.8*len(labels))]\n",
    "\n",
    "test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "test_labels = labels[int(0.8*len(labels)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "data_order = 'tf'  # 'th' for Theano, 'tf' for Tensorflow\n",
    "\n",
    "# check the order of data and chose proper data shape to save images\n",
    "if data_order == 'th':\n",
    "    train_shape = (len(train_addrs), 3, 144, 144)\n",
    "    test_shape = (len(test_addrs), 3, 144, 144)\n",
    "elif data_order == 'tf':\n",
    "    train_shape = (len(train_addrs), 144, 144, 3)\n",
    "    test_shape = (len(test_addrs), 144, 144, 3)\n",
    "\n",
    "# open a hdf5 file and create earrays\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "\n",
    "hdf5_file.create_dataset(\"train_img\", train_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"test_img\", test_shape, np.int8)\n",
    "\n",
    "hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "\n",
    "hdf5_file.create_dataset(\"train_labels\", (len(train_addrs),), np.int8)\n",
    "hdf5_file[\"train_labels\"][...] = train_labels\n",
    "hdf5_file.create_dataset(\"test_labels\", (len(test_addrs),), np.int8)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 1000/4684\n",
      "Train data: 2000/4684\n",
      "Train data: 3000/4684\n",
      "Train data: 4000/4684\n",
      "Test data: 1000/1172\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# a numpy array to save the mean of the images\n",
    "mean = np.zeros(train_shape[1:], np.float32)\n",
    "\n",
    "# loop over train addresses\n",
    "for i in range(len(train_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print('Train data: {0}/{1}'.format(i, len(train_addrs)))\n",
    "\n",
    "    # read an image and resize to (144, 144)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = train_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (144, 144), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # add any image pre-processing here\n",
    "\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "\n",
    "    # save the image and calculate the mean so far\n",
    "    hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "    mean += img / float(len(train_labels))\n",
    "\n",
    "# loop over test addresses\n",
    "for i in range(len(test_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print('Test data: {0}/{1}'.format(i, len(test_addrs)))\n",
    "\n",
    "    # read an image and resize to (144, 144)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = test_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (144, 144), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # add any image pre-processing here\n",
    "\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "\n",
    "    # save the image\n",
    "    hdf5_file[\"test_img\"][i, ...] = img[None]\n",
    "\n",
    "# save the mean and close the hdf5 file\n",
    "hdf5_file[\"train_mean\"][...] = mean\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "hdf5_path = 'chest_xray.hdf5'\n",
    "subtract_mean = False\n",
    "\n",
    "# open the hdf5 file\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "# subtract the training mean\n",
    "if subtract_mean:\n",
    "    mm = hdf5_file[\"train_mean\"][0, ...]\n",
    "    mm = mm[np.newaxis, ...]\n",
    "\n",
    "# Total number of samples\n",
    "data_num = hdf5_file[\"train_img\"].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from random import shuffle\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 100\n",
    "nb_class = 2\n",
    "\n",
    "# create list of batches to shuffle the data\n",
    "batches_list = list(range(int(ceil(float(data_num) / batch_size))))\n",
    "shuffle(batches_list)\n",
    "\n",
    "# loop over batches\n",
    "for n, i in enumerate(batches_list):\n",
    "    i_s = i * batch_size  # index of the first image in this batch\n",
    "    i_e = min([(i + 1) * batch_size, data_num])  # index of the last image in this batch\n",
    "\n",
    "    # read batch images and remove training mean\n",
    "    images = hdf5_file[\"train_img\"][i_s:i_e, ...]\n",
    "    if subtract_mean:\n",
    "        images -= mm\n",
    "\n",
    "    # read labels and convert to one hot encoding\n",
    "    labels = hdf5_file[\"train_labels\"][i_s:i_e]\n",
    "    labels_one_hot = np.zeros((batch_size, nb_class))\n",
    "    labels_one_hot[np.arange(batch_size), labels] = 1\n",
    "\n",
    "    print(n+1, '/', len(batches_list))\n",
    "\n",
    "    print(labels[0], labels_one_hot[0, :])\n",
    "    plt.imshow(images[0])\n",
    "    plt.show()\n",
    "\n",
    "    if n == 5:  # break after 5 batches\n",
    "        break\n",
    "\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
